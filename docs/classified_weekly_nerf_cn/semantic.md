
每周分类神经辐射场 - semantic ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
=====================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## Jul31 - Aug6, 2022
  - [NeSF: 用于 3D 场景的可概括语义分割的神经语义场](https://research.google/pubs/pub51563/) | [code]
    > 我们提出了 NeSF，一种从预训练的密度场和稀疏的 2D 语义监督产生 3D 语义场的方法。我们的方法通过利用将 3D 信息存储在神经域中的神经表示来避开传统的场景表示。尽管仅由 2D 信号监督，我们的方法能够从新颖的相机姿势生成 3D 一致的语义图，并且可以在任意 3D 点进行查询。值得注意的是，NeSF 与任何产生密度场的方法兼容，并且随着预训练密度场质量的提高，其准确性也会提高。我们的实证分析证明了在令人信服的合成场景上与竞争性 2D 和 3D 语义分割基线相当的质量，同时还提供了现有方法无法提供的功能。
## Jul24 - Jul30, 2022
## Previous weeks
  - [节食 NeRF：语义一致的 Few-Shot 视图合成, ICCV2021](https://www.ajayj.com/dietnerf) | [***``[code]``***](https://github.com/ajayjain/DietNeRF)
    > 我们提出了 DietNeRF，一种从几张图像估计的 3D 神经场景表示。神经辐射场 (NeRF) 通过多视图一致性学习场景的连续体积表示，并且可以通过光线投射从新颖的视点进行渲染。虽然 NeRF 在给定许多图像的情况下具有令人印象深刻的重建几何和精细细节的能力，对于具有挑战性的 360° 场景最多可重建 100 个，但当只有少数输入视图可用时，它通常会为其图像重建目标找到退化的解决方案。为了提高few-shot质量，我们提出了DietNeRF。我们引入了一种辅助语义一致性损失，它鼓励以新颖的姿势进行逼真的渲染。 DietNeRF 在单个场景上进行训练，以 (1) 从相同的姿势正确渲染给定的输入视图，以及 (2) 在不同的随机姿势中匹配高级语义属性。我们的语义损失使我们能够从任意姿势监督 DietNeRF。我们使用预训练的视觉编码器提取这些语义，例如 CLIP，这是一种视觉转换器，通过自然语言监督从网络挖掘出的数亿张不同的单视图 2D 照片进行训练。在实验中，DietNeRF 在从头开始学习时提高了少镜头视图合成的感知质量，在多视图数据集上进行预训练时，可以用少至一张观察到的图像渲染新视图，并生成完全未观察到的区域的合理完成。
  - [物体辐射场的无监督发现, ICLR2022](https://arxiv.org/abs/2107.07905) | [code]
    > 我们研究从单个图像推断以对象为中心的场景表示的问题，旨在推导出解释图像形成过程的表示，捕捉场景的 3D 性质，并且在没有监督的情况下学习。由于将复杂的 3D 到 2D 图像形成过程集成到强大的推理方案（如深度网络）中存在根本性挑战，大多数现有的场景分解方法都缺乏这些特征中的一个或多个。在本文中，我们提出了对象辐射场 (uORF) 的无监督发现，将神经 3D 场景表示和渲染的最新进展与深度推理网络相结合，用于无监督 3D 场景分解。在没有注释的多视图 RGB 图像上进行训练，uORF 学习从单个图像分解具有不同纹理背景的复杂场景。我们展示了 uORF 在无监督 3D 场景分割、新视图合成和三个数据集上的场景编辑方面表现良好。
  - [使用隐式场景表示进行就地场景标记和理解, ICCV2021(oral)](https://shuaifengzhi.com/Semantic-NeRF/) | [***``[code]``***](https://github.com/Harry-Zhi/semantic_nerf/)
    > 语义标签与几何和辐射重建高度相关，因为具有相似形状和外观的场景实体更有可能来自相似的类别。最近的隐式神经重建技术很有吸引力，因为它们不需要事先的训练数据，但同样的完全自我监督的方法对于语义来说是不可能的，因为标签是人类定义的属性。
