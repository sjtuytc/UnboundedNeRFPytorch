
每周分类神经辐射场 - lighting ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
=====================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## 大部分为机器翻译，少数论文手动翻译，有翻译错误可以PR修复。
## Jul31 - Aug6, 2022
## Jul24 - Jul30, 2022
  - [具有全局照明的可重新照明的新视图合成的神经辐射转移场](https://arxiv.org/abs/2207.13607) | [code]
    > 给定场景的一组图像，从新颖的视图和光照条件重新渲染该场景是计算机视觉和图形学中一个重要且具有挑战性的问题。一方面，计算机视觉中的大多数现有作品通常对图像形成过程施加许多假设，例如直接照明和预定义的材料，使场景参数估计易于处理。另一方面，成熟的计算机图形学工具允许在给定所有场景参数的情况下对复杂的照片般逼真的光传输进行建模。结合这些方法，我们提出了一种通过学习神经预计算辐射传递函数来在新视图下重新点亮场景的方法，该函数使用新的环境图隐式处理全局光照效果。我们的方法可以在单一未知照明条件下对一组场景的真实图像进行单独监督。为了在训练期间消除任务的歧义，我们在训练过程中紧密集成了一个可微的路径跟踪器，并提出了合成 OLAT 和真实图像损失的组合。结果表明，与当前技术水平相比，场景参数的恢复解缠结得到了显着改善，因此，我们的重新渲染结果也更加真实和准确。
## Previous weeks
  - [野外的 NeRF：无约束照片集的神经辐射场, CVPR2021](https://arxiv.org/abs/2008.02268) | [code]
    > 我们提出了一种基于学习的方法，用于仅使用野外照片的非结构化集合来合成复杂场景的新视图。我们建立在神经辐射场 (NeRF) 的基础上，它使用多层感知器的权重将场景的密度和颜色建模为 3D 坐标的函数。虽然 NeRF 在受控设置下捕获的静态对象的图像上效果很好，但它无法在不受控的图像中模拟许多普遍存在的真实世界现象，例如可变照明或瞬态遮挡物。我们为 NeRF 引入了一系列扩展来解决这些问题，从而能够从互联网上获取的非结构化图像集合中进行准确的重建。我们将我们的系统（称为 NeRF-W）应用于著名地标的互联网照片集，并展示时间一致的新颖视图渲染，这些渲染比现有技术更接近真实感。
  - [Ha-NeRF：野外的幻觉神经辐射场, CVPR2022](https://rover-xingyu.github.io/Ha-NeRF/) | [***``[code]``***](https://github.com/rover-xingyu/Ha-NeRF)
    > 神经辐射场 (NeRF) 最近因其令人印象深刻的新颖视图合成能力而广受欢迎。本文研究了幻觉 NeRF 的问题：即在一天中的不同时间从一组旅游图像中恢复一个真实的 NeRF。现有的解决方案采用具有可控外观嵌入的 NeRF 在各种条件下渲染新颖的视图，但它们无法渲染具有看不见的外观的视图一致图像。为了解决这个问题，我们提出了一个用于构建幻觉 NeRF 的端到端框架，称为 Ha-NeRF。具体来说，我们提出了一个外观幻觉模块来处理随时间变化的外观并将它们转移到新的视图中。考虑到旅游图像的复杂遮挡，我们引入了一个反遮挡模块来准确地分解静态主体以获得可见性。合成数据和真实旅游照片集的实验结果表明，我们的方法可以产生幻觉，并从不同的视图呈现无遮挡的图像。
  - [黑暗中的 NeRF：来自嘈杂原始图像的高动态范围视图合成, CVPR2022(oral)](https://bmild.github.io/rawnerf/) | [***``[code]``***](https://github.com/google-research/multinerf)
    > 神经辐射场 (NeRF) 是一种从姿势输入图像的集合中合成高质量新颖视图的技术。与大多数视图合成方法一样，NeRF 使用色调映射低动态范围（LDR）作为输入；这些图像已由有损相机管道处理，该管道可以平滑细节、剪辑高光并扭曲原始传感器数据的简单噪声分布。我们将 NeRF 修改为直接在线性原始图像上进行训练，保留场景的完整动态范围。通过从生成的 NeRF 渲染原始输出图像，我们可以执行新颖的高动态范围 (HDR) 视图合成任务。除了改变相机视角之外，我们还可以在事后操纵焦点、曝光和色调映射。尽管单个原始图像看起来比后处理的图像噪声大得多，但我们表明 NeRF 对原始噪声的零均值分布具有高度鲁棒性。当针对许多嘈杂的原始输入 (25-200) 进行优化时，NeRF 生成的场景表示非常准确，以至于其渲染的新颖视图优于在相同宽基线输入图像上运行的专用单图像和多图像深度原始降噪器。因此，我们的方法（我们称为 RawNeRF）可以从在近黑暗中捕获的极其嘈杂的图像中重建场景。
  - [NeRV：用于重新照明和视图合成的神经反射率和可见性场, CVPR2021](https://pratulsrinivasan.github.io/nerv/) | [code]
    > 我们提出了一种方法，该方法将由不受约束的已知照明照明的场景的一组图像作为输入，并生成可以在任意照明条件下从新视点渲染的 3D 表示作为输出。我们的方法将场景表示为参数化为 MLP 的连续体积函数，其输入是 3D 位置，其输出是该输入位置的以下场景属性：体积密度、表面法线、材料参数、到任何方向上第一个表面交点的距离，以及任何方向的外部环境的可见性。总之，这些允许我们在任意照明下渲染物体的新视图，包括间接照明效果。预测的能见度和表面相交场对于我们的模型在训练期间模拟直接和间接照明的能力至关重要，因为先前工作使用的蛮力技术对于具有单灯的受控设置之外的照明条件是难以处理的。我们的方法在恢复可重新照明的 3D 场景表示方面优于替代方法，并且在对先前工作构成重大挑战的复杂照明设置中表现良好。
  - [NeX：具有神经基础扩展的实时视图合成, CVPR2021(oral)](https://nex-mpi.github.io/) | [***``[code]``***](https://github.com/nex-mpi/nex-code/)
    > 我们提出了 NeX，这是一种基于多平面图像 (MPI) 增强的新型视图合成的新方法，可以实时再现 NeXt 级别的视图相关效果。与使用一组简单 RGBα 平面的传统 MPI 不同，我们的技术通过将每个像素参数化为从神经网络学习的基函数的线性组合来模拟视图相关的效果。此外，我们提出了一种混合隐式-显式建模策略，该策略改进了精细细节并产生了最先进的结果。我们的方法在基准前向数据集以及我们新引入的数据集上进行了评估，该数据集旨在测试与视图相关的建模的极限，具有明显更具挑战性的效果，例如 CD 上的彩虹反射。我们的方法在这些数据集的所有主要指标上都取得了最好的总体得分，渲染时间比现有技术快 1000 倍以上。
  - [NeRFactor：未知光照下形状和反射率的神经分解, TOG 2021 (Proc. SIGGRAPH Asia)](https://xiuming.info/projects/nerfactor/) | [code]
    > 我们解决了从由一种未知光照条件照射的物体的多视图图像（及其相机姿势）中恢复物体的形状和空间变化反射率的问题。这使得能够在任意环境照明下渲染对象的新颖视图并编辑对象的材质属性。我们方法的关键，我们称之为神经辐射分解（NeRFactor），是提取神经辐射场（NeRF）的体积几何[Mildenhall et al。 2020] 将对象表示为表面表示，然后在解决空间变化的反射率和环境照明的同时联合细化几何。具体来说，NeRFactor 在没有任何监督的情况下恢复表面法线、光能见度、反照率和双向反射分布函数 (BRDF) 的 3D 神经场，仅使用重新渲染损失、简单的平滑先验和从真实数据中学习的数据驱动的 BRDF 先验-世界BRDF测量。通过显式建模光可见性，NeRFactor 能够从反照率中分离出阴影，并在任意光照条件下合成逼真的软阴影或硬阴影。 NeRFactor 能够恢复令人信服的 3D 模型，用于在合成场景和真实场景的这种具有挑战性且约束不足的捕获设置中进行自由视点重新照明。定性和定量实验表明，NeRFactor 在各种任务中都优于经典和基于深度学习的最新技术。我们的视频、代码和数据可在 people.csail.mit.edu/xiuming/projects/nerfactor/ 上找到。
  - [Fig-NeRF：用于 3D 对象类别建模的图地面神经辐射场, 3DV2021](https://fig-nerf.github.io/) | [code]
    > 我们研究使用神经辐射场 (NeRF) 从输入图像的集合中学习高质量的 3D 对象类别模型。与以前的工作相比，我们能够做到这一点，同时将前景对象与不同的背景分开。我们通过 2 分量 NeRF 模型 FiG-NeRF 实现了这一点，该模型更喜欢将场景解释为几何恒定的背景和代表对象类别的可变形前景。我们表明，这种方法可以仅使用光度监督和随意捕获的对象图像来学习准确的 3D 对象类别模型。此外，我们的两部分分解允许模型执行准确和清晰的模态分割。我们使用合成的、实验室捕获的和野外数据，通过视图合成和图像保真度指标对我们的方法进行定量评估。我们的结果证明了令人信服的 3D 对象类别建模，其性能超过了现有方法的性能。
  - [NerfingMVS：室内多视角立体神经辐射场的引导优化, ICCV2021(oral)](https://arxiv.org/abs/2109.01129) | [***``[code]``***](https://github.com/weiyithu/NerfingMVS)
    > 在这项工作中，我们提出了一种新的多视图深度估计方法，该方法在最近提出的神经辐射场 (NeRF) 上利用了传统的 SfM 重建和基于学习的先验。与现有的依赖于估计对应的基于神经网络的优化方法不同，我们的方法直接优化隐式体积，消除了在室内场景中匹配像素的挑战性步骤。我们方法的关键是利用基于学习的先验来指导 NeRF 的优化过程。我们的系统首先通过微调其稀疏 SfM 重建来适应目标场景上的单目深度网络。然后，我们证明了 NeRF 的形状-辐射模糊性仍然存在于室内环境中，并建议通过采用适应的深度先验来监控体绘制的采样过程来解决这个问题。最后，通过对渲染图像进行误差计算获得的每像素置信度图可用于进一步提高深度质量。实验表明，我们提出的框架在室内场景中显着优于最先进的方法，在基于对应的优化和基于 NeRF 的优化对适应深度先验的有效性方面提出了令人惊讶的发现。此外，我们表明引导优化方案不会牺牲神经辐射场的原始合成能力，提高了可见视图和新视图的渲染质量。
