
每周分类神经辐射场 - others ![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)
===================================================================================================================================
## 按类别筛选: 
 [全部](../weekly_nerf_cn.md) | [动态](./dynamic.md) | [编辑](./editing.md) | [快速](./fast.md) | [泛化](./generalization.md) | [人体](./human.md) | [视频](./video.md) | [光照](./lighting.md) | [重建](./reconstruction.md) | [纹理](./texture.md) | [语义](./semantic.md) | [姿态-SLAM](./pose-slam.md) | [其他](./others.md) 
## 大部分为机器翻译，少数论文手动翻译，有翻译错误可以PR修复。
## Jul31 - Aug6, 2022
## Jul24 - Jul30, 2022
  - [DoF-NeRF：景深与神经辐射场相遇, ACMMM2022](https://arxiv.org/pdf/2208.00945) | [***``[code]``***](https://github.com/zijinwuzijin/DoF-NeRF)
    > 神经辐射场 (NeRF) 及其变体在表示 3D 场景和合成逼真的新颖视图方面取得了巨大成功。但是，它们通常基于针孔相机模型并假设全焦点输入。这限制了它们的适用性，因为从现实世界捕获的图像通常具有有限的景深 (DoF)。为了缓解这个问题，我们引入了 DoF-NeRF，一种新颖的神经渲染方法，可以处理浅自由度输入并可以模拟自由度效果。特别是，它根据几何光学原理扩展了 NeRF 以模拟镜头的孔径。这样的物理保证允许 DoF-NeRF 操作具有不同焦点配置的视图。得益于显式光圈建模，DoF-NeRF 还可以通过调整虚拟光圈和焦点参数来直接操纵 DoF 效果。它是即插即用的，可以插入到基于 NeRF 的框架中。在合成数据集和真实世界数据集上的实验表明，DoF-NeRF 不仅在全焦点设置中的性能与 NeRF 相当，而且还可以合成以浅自由度输入为条件的全焦点新视图。还演示了 DoF-NeRF 在 DoF 渲染中的一个有趣应用。
  - [神经密度-距离场, ECCV2022](https://arxiv.org/abs/2207.14455) | [***``[code]``***](https://ueda0319.github.io/neddf/)
    > 神经领域在 3D 视觉任务中的成功现在是无可争辩的。遵循这一趋势，已经提出了几种针对视觉定位的方法（例如，SLAM）来使用神经场估计距离或密度场。然而，仅通过基于密度场的方法（例如神经辐射场 (NeRF)）很难实现高定位性能，因为它们在大多数空白区域中不提供密度梯度。另一方面，基于距离场的方法，例如神经隐式表面 (NeuS)，在对象的表面形状方面存在局限性。本文提出了神经密度-距离场 (NeDDF)，这是一种新的 3D 表示，它相互约束距离和密度场。我们将距离场公式扩展到没有明确边界表面的形状，例如毛皮或烟雾，这使得从距离场到密度场的显式转换成为可能。通过显式转换实现的一致距离和密度场既能保证初始值的鲁棒性，又能实现高质量的配准。此外，场之间的一致性允许从稀疏点云快速收敛。实验表明，NeDDF 可以实现高定位性能，同时在新颖的视图合成上提供与 NeRF 相当的结果。该代码可在此 https URL 获得。
  - [通过 NeRF Attention 进行端到端视图合成](https://arxiv.org/abs/2207.14741) | [code]
    > 在本文中，我们提出了一个用于视图合成的简单 seq2seq 公式，其中我们将一组光线点作为输入和输出与光线相对应的颜色。在这个 seq2seq 公式上直接应用标准转换器有两个限制。首先，标准注意力不能成功地适应体积渲染过程，因此合成视图中缺少高频分量。其次，将全局注意力应用于所有光线和像素是非常低效的。受神经辐射场 (NeRF) 的启发，我们提出了 NeRF 注意力 (NeRFA) 来解决上述问题。一方面，NeRFA 将体积渲染方程视为软特征调制过程。通过这种方式，特征调制增强了具有类似 NeRF 电感偏置的变压器。另一方面，NeRFA 执行多阶段注意力以减少计算开销。此外，NeRFA 模型采用光线和像素转换器来学习光线和像素之间的相互作用。 NeRFA 在四个数据集上展示了优于 NeRF 和 NerFormer 的性能：DeepVoxels、Blender、LLFF 和 CO3D。此外，NeRFA 在两种设置下建立了新的 state-of-the-art：单场景视图合成和以类别为中心的新颖视图合成。该代码将公开发布。
  - [神经链：从多视图图像中学习头发的几何形状和外观, ECCV2022](https://arxiv.org/pdf/2207.14067) | [***``[code]``***](https://radualexandru.github.io/neural_strands/)
    > 我们提出了 Neural Strands，这是一种新颖的学习框架，用于从多视图图像输入中对精确的头发几何形状和外观进行建模。学习的头发模型可以从具有高保真视图相关效果的任何视点实时渲染。与体积模型不同，我们的模型实现了直观的形状和样式控制。为了实现这些特性，我们提出了一种基于神经头皮纹理的新型头发表示，该神经头皮纹理对每个纹素位置的单个股线的几何形状和外观进行编码。此外，我们引入了一种基于学习发束光栅化的新型神经渲染框架。我们的神经渲染是精确的和抗锯齿的，使渲染视图一致且逼真。将外观与多视图几何先验相结合，我们首次实现了从多视图设置中联合学习外观和显式头发几何形状。我们展示了我们的方法在各种发型的保真度和效率方面的有效性。
  - [拉普拉斯系统的神经格林函数, Computer & Graphics](https://www.sciencedirect.com/science/article/pii/S0097849322001406) | [code]
    > 求解源自拉普拉斯算子的线性方程组是广泛应用的核心。由于线性系统的稀疏性，当解具有大量自由度时，通常采用迭代求解器，例如共轭梯度和多重网格。这些迭代求解器可以看作是拉普拉斯算子格林函数的稀疏近似。在本文中，我们提出了一种机器学习方法，该方法从边界条件中回归格林函数。这是通过格林函数实现的，该函数可以以多尺度方式有效地表示，从而大大降低了与密集矩阵表示相关的成本。此外，由于格林函数完全依赖于边界条件，因此训练所提出的神经网络不需要对线性系统的右侧进行采样。结果表明，我们的方法优于最先进的共轭梯度和多重网格方法。
  - [关于物理概念的可学习性：神经网络能理解什么是真](https://arxiv.org/abs/2207.12186) | [code]
    > 鉴于深度神经网络生成逼真的合成数据的卓越能力，我们重新审视了经典的信号到符号障碍。 DeepFakes 和欺骗突出了物理现实与其抽象表示之间联系的脆弱性，无论是由数字计算机还是生物代理学习。从一个广泛适用的抽象概念定义开始，我们表明标准的前馈架构只能捕获微不足道的概念，无论权重的数量和训练数据的数量如何，尽管它们是非常有效的分类器。另一方面，包含递归的架构可以代表更大的概念类别，但可能仍然无法从有限的数据集中学习它们。我们定性地描述了可以被用随机梯度下降变体训练的现代架构“理解”的概念类别，使用（自由能）拉格朗日来测量信息复杂性。然而，即使一个概念已经被理解，网络也无法将其理解传达给外部代理，除非通过持续的交互和验证。然后，我们将物理对象表征为抽象概念，并使用前面的分析来表明物理对象可以由有限架构编码。然而，为了理解物理概念，传感器必须提供持续令人兴奋的观察，而控制数据采集过程的能力是必不可少的（主动感知）。控制的重要性取决于形式，比听觉或化学感知更有益于视觉。最后，我们得出结论，可以在有限的时间内用有限的资源将物理实体绑定到数字身份，原则上解决了信号到符号的障碍问题，但我们强调了持续验证的必要性。
## Previous weeks
  - [NeRF：将场景表示为用于视图合成的神经辐射场, ECCV2020](https://arxiv.org/abs/2003.08934) | [***``[code]``***](http://tancik.com/nerf)
    > 我们提出了一种方法，该方法通过使用稀疏输入视图集优化底层连续体积场景函数，实现了合成复杂场景的新视图的最新结果。我们的算法使用全连接（非卷积）深度网络表示场景，其输入是单个连续 5D 坐标（空间位置（x,y,z）和观察方向（θ,φ）），其输出是该空间位置的体积密度和与视图相关的发射辐射。我们通过沿相机光线查询 5D 坐标来合成视图，并使用经典的体渲染技术将输出颜色和密度投影到图像中。因为体积渲染是自然可微的，所以优化我们的表示所需的唯一输入是一组具有已知相机姿势的图像。我们描述了如何有效地优化神经辐射场以渲染具有复杂几何形状和外观的场景的逼真的新颖视图，并展示了优于先前在神经渲染和视图合成方面的工作的结果。查看合成结果最好以视频形式观看，因此我们敦促读者观看我们的补充视频以进行令人信服的比较。
  - [野外的 NeRF：无约束照片集的神经辐射场, CVPR2021](https://arxiv.org/abs/2008.02268) | [code]
    > 我们提出了一种基于学习的方法，用于仅使用野外照片的非结构化集合来合成复杂场景的新视图。我们建立在神经辐射场 (NeRF) 的基础上，它使用多层感知器的权重将场景的密度和颜色建模为 3D 坐标的函数。虽然 NeRF 在受控设置下捕获的静态对象的图像上效果很好，但它无法在不受控的图像中模拟许多普遍存在的真实世界现象，例如可变照明或瞬态遮挡物。我们为 NeRF 引入了一系列扩展来解决这些问题，从而能够从互联网上获取的非结构化图像集合中进行准确的重建。我们将我们的系统（称为 NeRF-W）应用于著名地标的互联网照片集，并展示时间一致的新颖视图渲染，这些渲染比现有技术更接近真实感。
  - [Ha-NeRF：野外的幻觉神经辐射场, CVPR2022](https://rover-xingyu.github.io/Ha-NeRF/) | [***``[code]``***](https://github.com/rover-xingyu/Ha-NeRF)
    > 神经辐射场 (NeRF) 最近因其令人印象深刻的新颖视图合成能力而广受欢迎。本文研究了幻觉 NeRF 的问题：即在一天中的不同时间从一组旅游图像中恢复一个真实的 NeRF。现有的解决方案采用具有可控外观嵌入的 NeRF 在各种条件下渲染新颖的视图，但它们无法渲染具有看不见的外观的视图一致图像。为了解决这个问题，我们提出了一个用于构建幻觉 NeRF 的端到端框架，称为 Ha-NeRF。具体来说，我们提出了一个外观幻觉模块来处理随时间变化的外观并将它们转移到新的视图中。考虑到旅游图像的复杂遮挡，我们引入了一个反遮挡模块来准确地分解静态主体以获得可见性。合成数据和真实旅游照片集的实验结果表明，我们的方法可以产生幻觉，并从不同的视图呈现无遮挡的图像。
  - [Nerfies：可变形的神经辐射场, ICCV2021](https://arxiv.org/abs/2011.12948) | [code]
    > 我们提出了第一种能够使用从手机随便捕获的照片/视频来逼真地重建可变形场景的方法。我们的方法通过优化一个额外的连续体积变形场来增强神经辐射场 (NeRF)，该场将每个观察点扭曲成一个规范的 5D NeRF。我们观察到这些类似 NeRF 的变形场容易出现局部最小值，并为基于坐标的模型提出了一种从粗到细的优化方法，可以实现更稳健的优化。通过将几何处理和物理模拟的原理应用于类似 NeRF 的模型，我们提出了变形场的弹性正则化，进一步提高了鲁棒性。我们表明，我们的方法可以将随意捕获的自拍照片/视频转换为可变形的 NeRF 模型，允许从任意视角对主体进行逼真的渲染，我们称之为“nerfies”。我们通过使用带有两部手机的装备收集时间同步数据来评估我们的方法，从而在不同视点产生相同姿势的训练/验证图像。我们表明，我们的方法忠实地重建了非刚性变形的场景，并以高保真度再现了看不见的视图。
  - [D-NeRF：动态场景的神经辐射场, CVPR2021](https://arxiv.org/abs/2011.13961) | [***``[code]``***](https://github.com/albertpumarola/D-NeRF)
    > 将机器学习与几何推理相结合的神经渲染技术已成为从一组稀疏图像中合成场景新视图的最有前途的方法之一。其中，神经辐射场 (NeRF) 尤为突出，它训练深度网络将 5D 输入坐标（表示空间位置和观察方向）映射为体积密度和与视图相关的发射辐射。然而，尽管在生成的图像上实现了前所未有的真实感水平，但 NeRF 仅适用于静态场景，其中可以从不同的图像中查询相同的空间位置。在本文中，我们介绍了 D-NeRF，这是一种将神经辐射场扩展到动态域的方法，允许在场景中移动的 \emph{single} 相机的刚性和非刚性运动下重建和渲染物体的新图像。为此，我们将时间视为系统的附加输入，并将学习过程分为两个主要阶段：一个将场景编码为规范空间，另一个将这个规范表示映射到特定时间的变形场景。两种映射都是使用全连接网络同时学习的。一旦网络经过训练，D-NeRF 就可以渲染新颖的图像，同时控制相机视图和时间变量，从而控制对象的移动。我们展示了我们的方法在物体处​​于刚性、关节和非刚性运动的场景中的有效性。代码、模型权重和动态场景数据集将发布。
  - [用于单目 4D 面部头像重建的动态神经辐射场, CVPR2021](https://gafniguy.github.io/4D-Facial-Avatars/) | [***``[code]``***](https://github.com/gafniguy/4D-Facial-Avatars)
    > 我们提出了用于模拟人脸外观和动态的动态神经辐射场。对说话的人进行数字建模和重建是各种应用程序的关键组成部分。特别是对于 AR 或 VR 中的远程呈现应用，需要忠实再现外观，包括新颖的视点或头部姿势。与显式建模几何和材料属性或纯粹基于图像的最先进方法相比，我们引入了基于场景表示网络的头部隐式表示。为了处理面部的动态，我们将场景表示网络与低维可变形模型相结合，该模型提供对姿势和表情的显式控制。我们使用体积渲染从这种混合表示中生成图像，并证明这种动态神经场景表示只能从单目输入数据中学习，而不需要专门的捕获设置。在我们的实验中，我们表明这种学习的体积表示允许生成照片般逼真的图像，其质量超过了基于视频的最先进的重演方法的质量。
  - [PVA：像素对齐的体积化身, CVPR2021](https://volumetric-avatars.github.io/) | [code]
    > 逼真的人头的采集和渲染是一个极具挑战性的研究问题，对于虚拟远程呈现特别重要。目前，最高质量是通过在多视图数据上以个人特定方式训练的体积方法实现的。与更简单的基于网格的模型相比，这些模型更好地表示精细结构，例如头发。体积模型通常使用全局代码来表示面部表情，以便它们可以由一小组动画参数驱动。虽然这样的架构实现了令人印象深刻的渲染质量，但它们不能轻易地扩展到多身份设置。在本文中，我们设计了一种新颖的方法，用于在仅给定少量输入的情况下预测人头的体积化身。我们通过一种新颖的参数化实现跨身份的泛化，该参数化将神经辐射场与直接从输入中提取的局部像素对齐特征相结合，从而避免了对非常深或复杂网络的需求。我们的方法仅基于光度重新渲染损失以端到端的方式进行训练，无需明确的 3D 监督。我们证明我们的方法在质量方面优于现有的现有技术，并且能够生成忠实的面部表情多身份设置。
  - [用于人体建模的动画神经辐射场, ICCV2021](https://zju3dv.github.io/animatable_nerf/) | [***``[code]``***](https://github.com/zju3dv/animatable_nerf)
    > 本文解决了从多视图视频中重建可动画人体模型的挑战。最近的一些工作提出将非刚性变形场景分解为规范神经辐射场和一组将观察空间点映射到规范空间的变形场，从而使他们能够从图像中学习动态场景。然而，它们将变形场表示为平移矢量场或 SE(3) 场，这使得优化受到高度约束。此外，这些表示不能由输入运动明确控制。相反，我们引入了神经混合权重场来产生变形场。基于骨架驱动的变形，混合权重场与 3D 人体骨骼一起使用，以生成观察到规范和规范到观察的对应关系。由于 3D 人体骨骼更易观察，它们可以规范变形场的学习。此外，学习到的混合权重场可以与输入的骨骼运动相结合，以生成新的变形场来为人体模型设置动画。实验表明，我们的方法明显优于最近的人类合成方法。该代码将在 https://zju3dv.github.io/animatable_nerf/ 上提供。
  - [NeRF++：分析和改进神经辐射场](https://arxiv.org/abs/2010.07492) | [***``[code]``***](https://github.com/Kai-46/nerfplusplus;)
    > 神经辐射场 (NeRF) 为各种捕捉设置实现了令人印象深刻的视图合成结果，包括有界场景的 360 度捕捉以及有界和无界场景的前向捕捉。 NeRF 将表示视图不变不透明度和视图相关颜色体积的多层感知器 (MLP) 拟合到一组训练图像，并基于体积渲染技术对新视图进行采样。在这份技术报告中，我们首先评论了辐射场及其潜在的模糊性，即形状-辐射模糊度，并分析了 NeRF 在避免这种模糊性方面的成功。其次，我们解决了将 NeRF 应用于大规模、无界 3D 场景中对象的 360 度捕获所涉及的参数化问题。我们的方法在这种具有挑战性的场景中提高了视图合成保真度。此 https 网址提供了代码。
  - [动态场景的神经场景图, CVPR2021(oral)](https://arxiv.org/abs/2011.10379) | [***``[code]``***](https://github.com/princeton-computational-imaging/neural-scene-graphs)
    > 最近的隐式神经渲染方法表明，可以通过仅由一组 RGB 图像监督的预测其体积密度和颜色来学习复杂场景的准确视图合成。然而，现有方法仅限于学习将所有场景对象编码为单个神经网络的静态场景的有效表示，并且缺乏将动态场景表示和分解为单个场景对象的能力。在这项工作中，我们提出了第一个将动态场景分解为场景图的神经渲染方法。我们提出了一种学习的场景图表示，它对对象变换和辐射进行编码，以有效地渲染场景的新颖排列和视图。为此，我们学习隐式编码的场景，并结合联合学习的潜在表示来描述具有单个隐式函数的对象。我们在合成和真实汽车数据上评估所提出的方法，验证我们的方法学习动态场景 - 仅通过观察该场景的视频 - 并允许渲染具有看不见的对象集的新颖场景组合的新颖照片般逼真的视图看不见的姿势。
  - [使用隐式场景表示进行就地场景标记和理解, ICCV2021(oral)](https://shuaifengzhi.com/Semantic-NeRF/) | [***``[code]``***](https://github.com/Harry-Zhi/semantic_nerf/)
    > 语义标签与几何和辐射重建高度相关，因为具有相似形状和外观的场景实体更有可能来自相似的类别。最近的隐式神经重建技术很有吸引力，因为它们不需要事先的训练数据，但同样的完全自我监督的方法对于语义来说是不可能的，因为标签是人类定义的属性。
